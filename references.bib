@misc{bootlinUnderstandingLinuxRealtime2024,
  title = {Understanding {{Linux}} Real-Time with {{PREEMPT}}\_{{RT}} Training},
  author = {{Bootlin}},
  year = {2024},
  month = jan,
  urldate = {2024-01-31},
  abstract = {These slides are the training materials for Bootlin's Understanding Linux real-time with PREEMPT\_RT training course.},
  langid = {english}
}

@misc{brentdurandEasyWaysEliminate2013,
  title = {Easy {{Ways}} to {{Eliminate Backscatter}} in Your {{Photos}}},
  author = {{Brent Durand}},
  year = {2013},
  month = oct,
  journal = {Underwater Photography Guide},
  url = {https://www.uwphotographyguide.com/eliminate-backscatter-underwater},
  urldate = {2024-02-14},
  abstract = {Backscatter is the underwater photographer's arch nemesis. We've all taken shots riddled with the distracting white specs, whether they dot the whole picture or form two semi-circles on the edge of the frame. Backscatter can (and often does) destroy an otherwise-excellent image. The good news is that there are some universal techniques for eliminating backscatter that can be applied to a variety of composition styles, from macro to wide-angle. What is Backscatter?},
  langid = {english},
  file = {/Users/sid/Zotero/storage/SMGGXDRG/eliminate-backscatter-underwater.html}
}

@article{cannyComputationalApproachEdge1986a,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  author = {Canny, John},
  year = {1986},
  month = nov,
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {PAMI-8},
  number = {6},
  pages = {679--698},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.1986.4767851},
  url = {https://ieeexplore.ieee.org/document/4767851},
  urldate = {2024-05-02},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}

@inproceedings{decharetteFastReactiveControl2012,
  title = {Fast {{Reactive Control}} for {{Illumination Through Rain}} and {{Snow}}},
  booktitle = {2012 {{IEEE International Conference}} on {{Computational Photography}} ({{ICCP}})},
  author = {De Charette, Raoul and Tamburo, Robert and Barnum, Peter C. and Rowe, Anthony and Kanade, Takeo and Narasimhan, Srinivasa G.},
  year = {2012},
  month = apr,
  pages = {1--10},
  publisher = {IEEE},
  address = {Seattle, WA, USA},
  doi = {10.1109/ICCPhot.2012.6215217},
  url = {http://ieeexplore.ieee.org/document/6215217/},
  urldate = {2024-05-01},
  abstract = {During low-light conditions, drivers rely mainly on headlights to improve visibility. But in the presence of rain and snow, headlights can paradoxically reduce visibility due to light reflected off of precipitation back towards the driver. Precipitation also scatters light across a wide range of angles that disrupts the vision of drivers in oncoming vehicles. In contrast to recent computer vision methods that digitally remove rain and snow streaks from captured images, we present a system that will directly improve driver visibility by controlling illumination in response to detected precipitation. The motion of precipitation is tracked and only the space around particles is illuminated using fast dynamic control. Using a physics-based simulator, we show how such a system would perform under a variety of weather conditions. We build and evaluate a proof-of-concept system that can avoid water drops generated in the laboratory.},
  isbn = {978-1-4673-1662-0 978-1-4673-1660-6 978-1-4673-1661-3},
  file = {/Users/sid/Zotero/storage/X7JCN9JV/De Charette et al. - 2012 - Fast reactive control for illumination through rai.pdf}
}

@misc{HowDoesDLP,
  title = {How Does a {{DLP}} Projector Work?},
  journal = {ProjectorScreen.com},
  url = {https://www.projectorscreen.com/blog/How-does-a-DLP-projector-work},
  urldate = {2024-02-24},
  abstract = {A DLPâ„¢ projector is a projector that utilizes a DLP chipset to produce the image you see on your projector screen. The DLP chip was developed in 1987 by Larry Hornbeck of Texas Instruments. The first DLP projector to use this technology was so...},
  langid = {english}
}

@article{kalmanNewApproachLinear1960,
  title = {A {{New Approach}} to {{Linear Filtering}} and {{Prediction Problems}}},
  author = {Kalman, R. E.},
  year = {1960},
  month = mar,
  journal = {Journal of Basic Engineering},
  volume = {82},
  number = {1},
  pages = {35--45},
  issn = {0021-9223},
  doi = {10.1115/1.3662552},
  url = {https://asmedigitalcollection.asme.org/fluidsengineering/article/82/1/35/397706/A-New-Approach-to-Linear-Filtering-and-Prediction},
  urldate = {2024-02-28},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  langid = {english}
}

@article{kassSnakesActiveContour1988,
  title = {Snakes: {{Active Contour Models}}},
  shorttitle = {Snakes},
  author = {Kass, Michael and Witkin, Andrew and Terzopoulos, Demetri},
  year = {1988},
  month = jan,
  journal = {Int J Comput Vision},
  volume = {1},
  number = {4},
  pages = {321--331},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/BF00133570},
  url = {http://link.springer.com/10.1007/BF00133570},
  urldate = {2024-05-02},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@phdthesis{katieshepherdMachineVisionBased2023,
  type = {{{MEng Project Report}}},
  title = {Machine {{Vision Based Underwater Anti-Backscatter Lighting System}}},
  author = {{Katie Shepherd}},
  year = {2023},
  address = {York, UK},
  urldate = {2023-09-01},
  abstract = {When filming underwater, small spots of debris reflect the light from Unmanned Underwater Vehicles (UUVs) reducing the camera image quality, this is known as backscatter. The purpose of this project is to create a machine vision-based lighting system using a smart projector, to eliminate backscatter from a video feed. In this project, the foundational testing of this anti-backscatter lighting system has been conducted. Previously with the use of image processing on captured images, backscatter has been removed using variations of median filtering. However, this can leave areas of the image blurry where the backscatter has been removed and does not eliminate the backscatter when capturing the video live. In this project with the use of a Raspberry Pi, a high- quality camera and a smart projector, the bright areas of backscatter can be successfully removed in live video feeds. The camera feeds back the position of detected bright spots in the scene, and then black holes are projected in these positions to not illuminate the backscatter, hence eliminating it. The results from testing have found issues with parallax and camera depth perception which make projecting holes accurately very complex, and this needs to be addressed further in future work. The project demonstrates, that with the use of a machine vision-based lighting system, backscatter of a variety of shapes and sizes can be detected and then eliminated from the scene. This project is just the beginning of a larger goal to eliminate backscatter in an underwater environment, and with all the foundational testing conducted successfully in the air, the system is ready to be thoroughly experimented with underwater.},
  langid = {english},
  school = {University of York}
}

@article{kuhnHungarianMethodAssignment1955,
  title = {The {{Hungarian}} Method for the Assignment Problem},
  author = {Kuhn, H. W.},
  year = {1955},
  month = mar,
  journal = {Naval Research Logistics},
  volume = {2},
  number = {1-2},
  pages = {83--97},
  issn = {0028-1441, 1931-9193},
  doi = {10.1002/nav.3800020109},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/nav.3800020109},
  urldate = {2024-02-28},
  abstract = {Abstract             Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the ``assignment problem'' is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/Z6FTQB22/Kuhn - 1955 - The Hungarian method for the assignment problem.pdf}
}

@misc{maurorivaRaspberryPi4B2019,
  title = {Raspberry {{Pi 4B}}: {{Real-Time System}} Using {{Preempt-RT}} (Kernel 4.19.y)},
  author = {{Mauro Riva}},
  year = {2019},
  month = sep,
  journal = {LeMaRiva{\textbar}tech},
  url = {https://lemariva.com/blog/2019/09/raspberry-pi-4b-preempt-rt-kernel-419y-performance-test},
  urldate = {2024-03-01},
  abstract = {This article is about testing the performance of the Raspberry Pi 4B to run Python algorithms on a Standard and Preempt-RT patched kernel. A tutorial to patch Kernel v.4.19.y is also included. A benchmark based on the N-queens problem written in Python is used to analyse the performance of the different kernels.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/G3GUIX3U/raspberry-pi-4b-preempt-rt-kernel-419y-performance-test.html}
}

@misc{opencv,
  title = {About},
  author = {{OpenCV}},
  journal = {OpenCV},
  url = {https://opencv.org/about/},
  urldate = {2024-03-01},
  abstract = {OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being an Apache 2 licensed product, OpenCV makes it easy for businesses to utilize and modify the code.},
  langid = {american}
}

@misc{opencvOpenCVCvSimpleBlobDetector,
  title = {{{OpenCV}}: Cv::{{SimpleBlobDetector Class Reference}}},
  author = {{OpenCV}},
  url = {https://docs.opencv.org/4.9.0/d0/d7a/classcv_1_1SimpleBlobDetector.html},
  urldate = {2024-05-01},
  langid = {english},
  file = {/Users/sid/Zotero/storage/T7VYPJQ8/classcv_1_1SimpleBlobDetector.html}
}

@misc{raspberrypiltdPicamera2Library2024,
  title = {The {{Picamera2 Library}}},
  author = {{Raspberry Pi Ltd}},
  year = {2024},
  month = apr,
  publisher = {Raspberry Pi Ltd},
  url = {https://datasheets.raspberrypi.com/camera/picamera2-manual.pdf},
  urldate = {2024-04-01},
  langid = {english},
  file = {/Users/sid/Zotero/storage/WIVGAC59/The Picamera2 Library.pdf}
}

@misc{raspberrypiltdRaspberryPiUs,
  title = {Raspberry {{Pi}} - {{About}} Us},
  author = {{Raspberry Pi Ltd}},
  journal = {Raspberry Pi},
  url = {https://www.raspberrypi.com/about/},
  urldate = {2024-02-23},
  abstract = {Raspberry Pi makes inexpensive, small computers for home, industry, education and much more.},
  langid = {british}
}

@misc{reddigitalcinemaGlobalRollingShutters,
  title = {Global \& {{Rolling Shutters}}},
  author = {{RED Digital Cinema}},
  journal = {Global \& Rolling Shutters},
  url = {https://www.red.com/red-101/global-rolling-shutter},
  urldate = {2024-02-24},
  abstract = {A camera's shutter determines how and when light gets recorded during an exposure. In this article, we'll explore the various shutter mechanisms that have been implemented, ranging from early film to recent digital cameras.},
  file = {/Users/sid/Zotero/storage/MN6VK2MZ/global-rolling-shutter.html}
}

@misc{robertfisherConnectedComponentsLabeling2003,
  title = {Connected {{Components Labeling}}},
  author = {{Robert Fisher} and {Simon Perkins} and {Ashley Walker} and {Erik Wolfart}},
  year = {2003},
  journal = {Image Analysis - Connected Components Labeling},
  url = {https://homepages.inf.ed.ac.uk/rbf/HIPR2/label.htm},
  urldate = {2024-05-01},
  langid = {british},
  file = {/Users/sid/Zotero/storage/89SQ4FRG/label.html}
}

@misc{RollingShutterVs,
  title = {Rolling {{Shutter}} vs {{Global Shutter sCMOS Camera Mode}}},
  journal = {Oxford Instruments},
  url = {https://andor.oxinst.com/learning/view/article/rolling-and-global-shutter},
  urldate = {2024-02-24},
  abstract = {This article outlines the differences between Rolling Shutter vs Global Shutter camera modes. Discover the mode that best suits your needs},
  langid = {english},
  file = {/Users/sid/Zotero/storage/IY5G9II2/rolling-and-global-shutter.html}
}

@misc{rosebrockZeroparameterAutomaticCanny2015,
  title = {Zero-Parameter, Automatic {{Canny}} Edge Detection with {{Python}} and {{OpenCV}}},
  author = {Rosebrock, Adrian},
  year = {2015},
  month = apr,
  journal = {PyImageSearch},
  url = {https://pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/},
  urldate = {2024-05-16},
  abstract = {Don't tune your Canny edge detector parameters by hand. In this article, I'll show you my automatic, parameter free Canny edge detector.},
  langid = {american},
  file = {/Users/sid/Zotero/storage/VWJ2WIKM/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv.html}
}

@misc{sidharthshanmugamBackscattercancellationsystem2024,
  title = {Backscatter-Cancellation-System},
  shorttitle = {Sidharth-{{Shanmugam-MEng-Project-2023-24}}},
  author = {{Sidharth Shanmugam}},
  year = {2024},
  month = may,
  journal = {GitHub},
  url = {https://github.com/Sidharth-Shanmugam-MEng-Project-2023-24/backscatter-cancellation-system},
  urldate = {2024-05-19},
  langid = {english},
  file = {/Users/sid/Zotero/storage/CPTDGN74/main.html}
}

@misc{sidharthshanmugamBackscattercancellationsystemMultiprocessing2024,
  title = {Backscatter-Cancellation-System at Multiprocessing},
  shorttitle = {Sidharth-{{Shanmugam-MEng-Project-2023-24}}},
  author = {{Sidharth Shanmugam}},
  year = {2024},
  month = apr,
  journal = {GitHub},
  url = {https://github.com/Sidharth-Shanmugam-MEng-Project-2023-24/backscatter-cancellation-system/tree/multiprocessing},
  urldate = {2024-05-19},
  langid = {english},
  file = {/Users/sid/Zotero/storage/M52SDKCZ/multiprocessing.html}
}

@misc{sidharthshanmugamBubblebackscattersimulator2024,
  title = {Bubble-Backscatter-Simulator},
  shorttitle = {Sidharth-{{Shanmugam-MEng-Project-2023-24}}/Bubble-Backscatter-Simulator},
  author = {{Sidharth Shanmugam}},
  year = {2024},
  month = apr,
  journal = {GitHub},
  url = {https://github.com/Sidharth-Shanmugam-MEng-Project-2023-24/bubble-backscatter-simulator},
  urldate = {2024-05-19},
  abstract = {A Python script to generate bubble-based backscatter particles for virtually simulated testing and quantification.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/E95C6322/main.html}
}

@techreport{sidharthshanmugamInitialReportMachine2024,
  title = {Initial {{Report}}: {{Machine Vision-Based Anti-Backscatter Lighting System}} for {{Unmanned Underwater Vehicles}}},
  author = {{Sidharth Shanmugam}},
  year = {2024},
  month = mar,
  address = {York, UK},
  institution = {University of York},
  urldate = {2024-04-30},
  langid = {british}
}

@misc{sidharthshanmugamPicamvideorecorder2024,
  title = {Picam-Video-Recorder},
  shorttitle = {Sidharth-{{Shanmugam-MEng-Project-2023-24}}/Picam-Video-Recorder},
  author = {{Sidharth Shanmugam}},
  year = {2024},
  month = apr,
  journal = {GitHub},
  url = {https://github.com/Sidharth-Shanmugam-MEng-Project-2023-24/picam-video-recorder},
  urldate = {2024-05-19},
  abstract = {Python script to record video from a Raspberry Pi Camera stream to a file, simultaneously driving a projector light source using the Framebuffer.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/BF4XMSS5/main.html}
}

@incollection{tamburoProgrammableAutomotiveHeadlights2014,
  title = {Programmable {{Automotive Headlights}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2014},
  author = {Tamburo, Robert and Nurvitadhi, Eriko and Chugh, Abhishek and Chen, Mei and Rowe, Anthony and Kanade, Takeo and Narasimhan, Srinivasa G.},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  year = {2014},
  volume = {8692},
  pages = {750--765},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-10593-2_49},
  url = {http://link.springer.com/10.1007/978-3-319-10593-2_49},
  urldate = {2024-05-01},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-319-10592-5 978-3-319-10593-2},
  langid = {english},
  file = {/Users/sid/Zotero/storage/ZXPVI5JR/Tamburo et al. - 2014 - Programmable Automotive Headlights.pdf}
}

@article{thomanekAutomatedGasBubble2010,
  title = {Automated Gas Bubble Imaging at Sea Floor - a New Method of in Situ Gas Flux Quantification},
  author = {Thomanek, K. and Zielinski, O. and Sahling, H. and Bohrmann, G.},
  year = {2010},
  month = jun,
  journal = {Ocean Science},
  volume = {6},
  number = {2},
  pages = {549--562},
  publisher = {Copernicus GmbH},
  issn = {1812-0784},
  doi = {10.5194/os-6-549-2010},
  url = {https://os.copernicus.org/articles/6/549/2010/},
  urldate = {2024-02-24},
  abstract = {Photo-optical systems are common in marine sciences and have been extensively used in coastal and deep-sea research. However, due to technical limitations in the past photo images had to be processed manually or semi-automatically. Recent advances in technology have rapidly improved image recording, storage and processing capabilities which are used in a new concept of automated in situ gas quantification by photo-optical detection. The design for an in situ high-speed image acquisition and automated data processing system is reported ("Bubblemeter"). New strategies have been followed with regards to back-light illumination, bubble extraction, automated image processing and data management. This paper presents the design of the novel method, its validation procedures and calibration experiments. The system will be positioned and recovered from the sea floor using a remotely operated vehicle (ROV). It is able to measure bubble flux rates up to 10 L/min with a maximum error of 33\% for worst case conditions. The Bubblemeter has been successfully deployed at a water depth of 1023 m at the Makran accretionary prism offshore Pakistan during a research expedition with R/V Meteor in November 2007.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/9E67VFHD/Thomanek et al. - 2010 - Automated gas bubble imaging at sea floor &ndash; .pdf}
}

@misc{universityofhawaiiPracticesScienceUnderwater,
  title = {Practices of {{Science}}: {{Underwater Photography}} and {{Videography}}},
  author = {{University of Hawai`i}},
  journal = {Practices of Science: Underwater Photography and Videography {\textbar} manoa.hawaii.edu/ExploringOurFluidEarth},
  url = {https://manoa.hawaii.edu/exploringourfluidearth/physical/ocean-depths/light-ocean/practices-science-underwater-photography-and-videography},
  urldate = {2024-02-13},
  langid = {english},
  file = {/Users/sid/Zotero/storage/AZT4HY4D/practices-science-underwater-photography-and-videography.html}
}

@misc{WhatFPGAField,
  title = {What Is an {{FPGA}}? {{Field Programmable Gate Array}}},
  shorttitle = {What Is an {{FPGA}}?},
  journal = {AMD},
  url = {https://www.xilinx.com/products/silicon-devices/fpga/what-is-an-fpga.html},
  urldate = {2024-02-23},
  abstract = {What is an FPGA - Field Programmable Gate Arrays are semiconductor devices that are based around a matrix of configurable logic blocks (CLBs) connected via programmable interconnects. FPGAs can be reprogrammed to desired application or functionality requirements after manufacturing.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/BJ469M5J/what-is-an-fpga.html}
}

@book{yannickallardUnmannedUnderwaterVehicle2014,
  title = {Unmanned {{Underwater Vehicle}} ({{UUV}}) {{Information Study}}},
  author = {{Yannick Allard} and {Elisa Shahbazian}},
  year = {2014},
  month = nov,
  publisher = {Defence Research \& Development Canada, Atlantic Research Centre},
  url = {https://apps.dtic.mil/sti/pdfs/AD1004191.pdf},
  urldate = {2024-02-14},
  abstract = {Unmanned underwater vehicles UUV are any vehicles that are able to operate underwater without a human occupant. Smaller and cheaper autonomous underwater vehicles AUV are today very capable and gaining users. Large autonomous underwater vehicles are more expensive but they offer capabilities in some missions and applications that no other platforms can offer. However, using unmanned underwater vehicles in marine applications provide some challenges such as noisy communication, position uncertainty and the likelihood of robot failures. In addition, standards for data and information sharing are not well defined and, as mature as it is, the unmanned underwater vehicle field is still an emerging sector. Within the last decade, interest in UUV to be part of specific military, industrial and academic missions and applications have increased due to technological innovation and the evolution of their sensor payload. Missions such as persistent surveillance, anti-submarine warfare, oceanography and mine coutermeasure are amongst those where UUV capabilities far exceed those offered by other platforms. Canadas vast coastal areas could benefit from the introduction of UUVs to perform various roles. On one hand, their use is very cost-effective. On the other hand, they offer persistence and data quality that are not achievable using traditional methods. This usefulness is even more reflected in remote environments, where deploying personnel is a very costly alternatives. In order to enable the integration of the data and information provided by a UUV it is necessary to have a look in the underlying data and information sharing standards related to them. Achievement of interoperability between multiple national and international agencies is mandatory if one seeks to use the UUV to its full potential in support of the generation of more complete maritime domain awareness.},
  langid = {english}
}

@incollection{zelenkaGasBubbleShape2014a,
  title = {Gas {{Bubble Shape Measurement}} and {{Analysis}}},
  booktitle = {Pattern {{Recognition}}},
  author = {Zelenka, Claudius},
  editor = {Jiang, Xiaoyi and Hornegger, Joachim and Koch, Reinhard},
  year = {2014},
  volume = {8753},
  pages = {743--749},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-11752-2_63},
  url = {https://link.springer.com/10.1007/978-3-319-11752-2_63},
  urldate = {2024-05-02},
  isbn = {978-3-319-11751-5 978-3-319-11752-2},
  langid = {english}
}

@article{zhangUnderwaterBubbleEscape2023,
  title = {Underwater Bubble Escape Volume Measurement Based on Passive Acoustic under Noise Factors: {{Simulation}} and Experimental Research},
  shorttitle = {Underwater Bubble Escape Volume Measurement Based on Passive Acoustic under Noise Factors},
  author = {Zhang, Yu and Yu, Yao and Rui, Xiaobo and Feng, Zhu and Zhang, Jin and Chen, Yong and Qi, Lei and Chen, Xi and Zhou, Xueqian},
  year = {2023},
  month = feb,
  journal = {Measurement},
  volume = {207},
  pages = {112400},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2022.112400},
  url = {https://www.sciencedirect.com/science/article/pii/S0263224122015974},
  urldate = {2024-02-24},
  abstract = {Passive acoustic methods are suitable for long-term seabed gas leak monitoring with high accuracy under the condition of low cost and simple experimental equipment. However, the impact of noise in complex underwater environments poses great challenges for measurements. In this paper, aiming at the quantitative detection problem, a theoretical model of the bubble generation process by underwater gas escape is established, and the mechanism of bubble acoustic signal generation is clarified. The model identification of bubble volume oscillation is realized through the complementary ensemble empirical mode decomposition (CEEMD) method. Then continuous bubbles are segmented by the normalized energy method to achieve a high-precision measurement of volume inversion. A measurement prototype is developed and tested in the lake with multiple noises caused by seawater disturbance, sea wind, and ships. The results showed that the measurement errors could be kept within 10\% even under the condition of strong noise interference.},
  keywords = {Ambient noise,Bubble,Carbon capture and storage,Passive acoustics,Prototype platform},
  file = {/Users/sid/Zotero/storage/RS77YW33/S0263224122015974.html}
}
